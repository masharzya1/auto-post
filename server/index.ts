import express, { type Request, Response } from "express";
import { setupVite, log } from "./vite.js";
import OpenAI from "openai";
import { Anthropic } from "@anthropic-ai/sdk";
import { GoogleGenerativeAI } from "@google/generative-ai";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const app = express();
app.use(express.json());
app.use(express.urlencoded({ extended: false }));

// AI Generation Logic
app.post("/api/content/generate", async (req: Request, res: Response) => {
  const { type, niche, model, apiKey } = req.body;
  
  if (!apiKey) {
    return res.status(400).json({ error: "API Key is required for this model." });
  }

  try {
    if (type === "text") {
      let generatedText = "";
      const prompt = `Write a high-quality social media caption about ${niche}. Include relevant hashtags. Make it engaging and professional.`;
      
      if (model.includes("gpt")) {
        const openai = new OpenAI({ apiKey });
        const response = await openai.chat.completions.create({
          model: model,
          messages: [{ role: "user", content: prompt }],
        });
        generatedText = response.choices[0]?.message?.content || "";
      } else if (model.includes("claude")) {
        const anthropic = new Anthropic({ apiKey });
        const response = await anthropic.messages.create({
          model: model,
          max_tokens: 1024,
          messages: [{ role: "user", content: prompt }],
        });
        generatedText = response.content[0].type === 'text' ? response.content[0].text : "";
      } else if (model.includes("gemini")) {
        const genAI = new GoogleGenerativeAI(apiKey);
        const genModel = genAI.getGenerativeModel({ model: model.includes("pro") ? "gemini-1.5-pro" : "gemini-1.5-flash" });
        const result = await genModel.generateContent(prompt);
        generatedText = result.response.text();
      }

      const lines = generatedText.split("\n");
      const hashtags = lines[lines.length - 1].startsWith("#") ? lines.pop()?.split(" ").filter(t => t.startsWith("#")) : [];
      const text = lines.join("\n").trim();

      res.json({ 
        text: text || `AI Generated Caption for ${niche}`,
        hashtags: hashtags?.length ? hashtags.map(h => h.replace("#", "")) : [niche.toLowerCase(), "trending", "ai"]
      });
    } else {
      let imageUrl = "https://images.unsplash.com/photo-1618005182384-a83a8bd57fbe";
      if (model.includes("gpt")) {
         const openai = new OpenAI({ apiKey });
         const response = await openai.images.generate({
           model: "dall-e-3",
           prompt: `${niche} themed high-quality professional photography, cinematic lighting, ultra-detailed, 8k resolution`,
           n: 1,
           size: "1024x1024",
         });
         imageUrl = response.data?.[0]?.url || imageUrl;
      }
      
      res.json({
        url: imageUrl,
        prompt: `${niche} themed artwork generated by ${model}`
      });
    }
  } catch (error: any) {
    console.error("AI Generation Error:", error);
    res.status(500).json({ error: error.message });
  }
});

// Vercel deployment support
if (process.env.NODE_ENV === "production") {
  // Use "dist" instead of "dist/public" as per vite build output
  const distPath = path.join(__dirname, "..", "dist");
  app.use(express.static(distPath));
  app.get("*", (req, res) => {
    res.sendFile(path.join(distPath, "index.html"));
  });
} else {
  (async () => {
    await setupVite(app);
    const PORT = 5000;
    app.listen(PORT, "0.0.0.0", () => {
      log(`serving on port ${PORT}`);
    });
  })();
}

export default app;